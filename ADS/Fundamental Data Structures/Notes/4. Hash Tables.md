
| Term                        | Definition                                                                                                                               |
| --------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
| **Hash Table**              | A data structure consisting of a bucket array and a hash function, used to store key-value pairs for efficient lookup.                   |
| **Bucket Array**            | An array of size N where each cell (bucket) stores a collection of key-value pairs in a hash table.                                      |
| **Capacity**                | The size N of the bucket array in a hash table.                                                                                          |
| **Hash Function**           | A function mapping each key k to an integer in the range [0, N-1], where N is the capacity of the hash table.                            |
| **Collision**               | Occurs when two different keys have the same hash value, causing them to map to the same bucket.                                         |
| **Hash Code**               | The first part of a hash function that maps keys to integers.                                                                            |
| **Compression Function**    | The second part of a hash function that maps integers to the range [0, N-1].                                                             |
| **Division Method**         | A compression function that takes an integer modulo N.                                                                                   |
| **MAD Method**              | Multiply, Add, and Divide - a compression function where y maps to (ay + b) mod N, where a and b are nonnegative integers.               |
| **Separate Chaining**       | A collision resolution method where each bucket stores a list of all entries that hash to that bucket.                                   |
| **Open Addressing**         | A set of collision resolution methods where at most one entry is stored per bucket.                                                      |
| **Linear Probing**          | An open addressing method that, upon collision at bucket i, tries buckets (i+1) mod N, (i+2) mod N, etc., until finding an empty bucket. |
| **Quadratic Probing**       | An open addressing method that, upon collision at bucket i, tries buckets (i+jÂ²) mod N for j=0,1,2,..., until finding an empty bucket.   |
| **Secondary Clustering**    | A clustering pattern that occurs with quadratic probing.                                                                                 |
| **Double Hashing**          | An open addressing method that uses a secondary hash function h' to determine the step size between probes.                              |
| **Secondary Hash Function** | Used in double hashing, often defined as h'(k) = q - (k mod q), for a prime number q < N.                                                |
| **Tombstone**               | A marker left in a bucket after a key-value pair is deleted, to prevent disruption of future searches.                                   |
| **Local Reorganisation**    | A method to address the issue of tombstones by moving records into vacated buckets along the probe sequence.                             |
| **Rehashing**               | Periodically reinserting all records into a new hash table to improve performance and remove tombstones.                                 |

## 1. Hash Table Properties

A hash table has the following properties:
- A hash table consists of a bucket array and a hash function.
- A bucket array for a hash table is an array $A$ of size $N$, where each cell of $A$ is thought as a bucket storing a collection of key-value pairs.
- The size $N$ of the array is called the capacity of the hash table.

---

## 2. Hashing Function

A hash function $h$ is a function mapping each key $k$ to an integer in the range $[0,N-1]$, where $N$ is the capacity of the hash table. The main idea is to use $h(k)$ as an index into the bucket array $A$. That is we store the key-value pair $(k,v)$ in the bucket $A[h(k)]$. If there are 2 keys with the same hash value, then 2 different entries will be mapped to the same bucket in $A$. In this case, we say that a collision has occurred, which we will discuss later.

A hash function is usually specified as the composition of 2 functions:
- Hash code: keys to integers
- Compression function: integers to $[0,N-1]$
The hash code is applied first, and the compression function is applied next on the result, the goal of the hash function is the disperse the keys in an apparently random way.

A hash function should be efficiently computable, and each table position equally likely for each key. 

Some compression functions:
- Division: take integer mod $N$
- Multiply add and divide (MAD): $y$ maps to $ay+B$ mod $N$ where $a$ and $b$ are nonnegative integers.

---

## 3. Hash Function Collisions

A collision is when 2 keys hash to the same integer in the table, essentially meaning both data items wish to be in the same slot in the hash table which obviously cannot happen. So, there are several ways to deal with collisions. Whichever method we choose to deal with them, a large number of collisions reduces the performance of the hash table. A good hash function minimises the collisions as much as possible.

There are 4 methods we will explore:
- Separate chaining 
- Linear probing (open addressing)
- Quadratic probing (open addressing)
- Double hashing (open addressing)

---

## 4. Separate Chaining

Each bucket $A[i]$ stores a list holding the entries $(k,v)$ such that $h(k)=i$. This just means that each bucket in the hash table holds a list of values rather than just 1. And the performance of this method is directly related to the amount of elements in each bucket, if there is 5 elements in 1 bucket then you may have to search through all 5 to find the one you're looking for and this can be rather slow.

The average length of a bucket is $N/M$ where $N$ = number of keys you're trying to store, $M$ = size of array. So for an array of size $1000$, and trying to input $100$ keys we would on average have $10$ elements in each bucket.

The worst case scenario is that all keys would be hashed to the same bucket.

---

## 5. Linear Probing

In linear probing, if we try to insert an element $(k,v)$ into a bucket $A[i]$ that has already got an element in, where $i=h(k)$, then we try next at $A[(i+1) \space mod \space N]$. If $A[(i+1) \space mod \space N]$ is occupied then we try $A[(i+2) \space mod \space N]$, and so on, until we find an empty bucket.

Insert and search cost depend on the length of cluster. A cluster is when multiple keys are hashed to the same place and so they form a large contiguous block. The average length of a cluster is $N/M$. The worst case scenario is when all keys hash to the same cluster.

---

## 6. Quadratic Probing

Quadratic probing iteratively tries the buckets $A[(i+f(j)) \space mod \space N]$, for $j=0,1,2,...$ Where $f(j)=j^2$ until we find an empty bucket. Quadratic probing avoids clustering patterns that occur with linear probing. However, it creates its own kind of clustering called secondary clustering. 

The quadratic probing strategy may not find an empty bucket in $A$ even if one exists.

---

## 7. Double Hashing

In this approach, we choose a secondary hash function, $h'$, and if $h$ maps some key $k$ to a bucket $A[i]$, with $i=h(k)$, that is already occupied, then we iteratively try the buckets: $A[(i+f(j)) \space mod \space N]$ for $j=0,1,2,...,$ where $f(j)=j \cdot h'(k)$ 

A common choice for $h'(k)=q-(k \space mod \space q)$, for some prime number $q < N$. This function should not evaluate to 0. The reason why $q$ should be prime is so that hashing functions definitely visits every bucket and doesn't miss any on an infinite run.

---

## 8. Deletions & Tombstones

Deletions from the hash table must not hinder future searches. If a bucket is simply left empty this will hinder future probes. But the bucket should not be left unusable. To solve these problems we use a $tombstone$; a marker left in a bucket after a deletion. If a tombstone is encountered when searching along a probe sequence to find a key, we know to ignore it. If a tombstone is encountered during insertion, then we should continue probing (to avoid creating duplicates), but then the new record can be placed in the bucket where the tombstone was found.

The use of tombstones lengthens the average probe sequence distance. Two possible remedies for this are as follows:
- Local reorganisation: after deleting a key, continue to follow the probe sequence of that key and move records into the vacated bucket. (This will not work for all collision resolution policies).
- Periodically rehash the table by reinserting all records into a new hash table. And if you have a record of which keys are accessed most these can be placed where they will be found most easily.

